import{_ as s,c as a,o as n,aA as t}from"./chunks/framework.Gq9Ydw09.js";const o=JSON.parse('{"title":"","description":"","frontmatter":{"layout":"home","hero":{"name":"DRiL.jl","text":"Deep Reinforcement Learning in Julia","tagline":"Fast, flexible, and easy-to-use deep RL algorithms","image":{"src":"/logo.png","alt":"DRiL.jl"},"actions":[{"theme":"brand","text":"Getting Started","link":"/getting_started"},{"theme":"alt","text":"API Reference","link":"/api"},{"theme":"alt","text":"View on GitHub","link":"https://github.com/KristianHolme/DRiL.jl"}]},"features":[{"icon":"ðŸš€","title":"Fast & Extensible","details":"Built on Lux.jl for efficient neural networks with automatic differentiation. Pure Julia for easy customization."},{"icon":"ðŸŽ®","title":"Flexible Environments","details":"Comprehensive interface supporting discrete and continuous action spaces with parallel execution."},{"icon":"ðŸ“Š","title":"Rich Logging","details":"TensorBoard and Weights & Biases integration for real-time training monitoring and analysis."},{"icon":"âš¡","title":"Production-Ready","details":"Extract lightweight deployment policies. Save and load normalization statistics for consistent inference."}]},"headers":[],"relativePath":"index.md","filePath":"index.md","lastUpdated":null}'),l={name:"index.md"};function e(h,i,p,k,r,d){return n(),a("div",null,[...i[0]||(i[0]=[t("",4)])])}const g=s(l,[["render",e]]);export{o as __pageData,g as default};
